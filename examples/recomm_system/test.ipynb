{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n",
      "Original data shape: (1465, 16)\n",
      "Expanded data shape: (14640, 4)\n",
      "Dataset saved to noisy_dataset_0.005.csv\n",
      "Creating training data\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n",
      "Original data shape: (1465, 16)\n",
      "Expanded data shape: (14640, 4)\n",
      "Dataset saved to noisy_dataset_0.01.csv\n",
      "Creating training data\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n",
      "Original data shape: (1465, 16)\n",
      "Expanded data shape: (14640, 4)\n",
      "Dataset saved to noisy_dataset_0.02.csv\n",
      "Creating training data\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n",
      "Original data shape: (1465, 16)\n",
      "Expanded data shape: (14640, 4)\n",
      "Dataset saved to noisy_dataset_0.05.csv\n",
      "Creating training data\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n",
      "Original data shape: (1465, 16)\n",
      "Expanded data shape: (14640, 4)\n",
      "Dataset saved to noisy_dataset_0.1.csv\n",
      "Creating training data\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: /root/.cache/kagglehub/datasets/karkavelrajaj/amazon-sales-dataset/versions/1\n",
      "Original data shape: (1465, 16)\n",
      "Expanded data shape: (14640, 4)\n",
      "Dataset saved to noisy_dataset_0.2.csv\n"
     ]
    }
   ],
   "source": [
    "import prepare_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset_noise_ratios = [0.005,0.01,0.02,0.05,0.1,0.2]\n",
    "for noise in dataset_noise_ratios:\n",
    "    data = prepare_dataset.aug_amazon_products(noise_ratio = noise)\n",
    "    df = pd.DataFrame(data)\n",
    "    noise_dataset_file = f\"noisy_dataset_{noise}.csv\"\n",
    "    if os.path.exists(noise_dataset_file):\n",
    "        df.to_csv(noise_dataset_file, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        df.to_csv(noise_dataset_file, index=False)\n",
    "    print(f\"Dataset saved to {noise_dataset_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "\\textbf{Noise Ratio} & \\textbf{GCN (\\%)} & \\textbf{GTM (\\%)} & \\textbf{TMClassifier (\\%)} \\\\ \\hline\n",
      "0.005 & 83.39 & 98.73 & 76.73 \\\\ \\hline\n",
      "0.01 & 85.55 & 98.35 & 74.87 \\\\ \\hline\n",
      "0.02 & 83.57 & 97.73 & 72.24 \\\\ \\hline\n",
      "0.05 & 82.13 & 94.61 & 63.86 \\\\ \\hline\n",
      "0.1 & 75.93 & 89.85 & 49.48 \\\\ \\hline\n",
      "0.2 & 64.12 & 78.73 & 20.13 \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\caption{Average accuracy comparison of GCN, GraphTM, and TMClassifier for varying noise ratios.}\n",
      "\\label{tab:recomm_sys_accuracy}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"experiment_results.csv\")\n",
    "exp_id = \"20250409090514\" \n",
    "data['Exp_id'] = data['Exp_id'].astype(str)\n",
    "filtered_data = data[data['Exp_id'] == exp_id]\n",
    "# print(filtered_data)\n",
    "\n",
    "# Create a dictionary to store the accuracy values\n",
    "noise_accuracies = {}\n",
    "\n",
    "# Algorithm,Noise_Ratio,T,s,Max_Included_Literals,Epochs,Platform,Total_Time,Accuracy\n",
    "# Group the data by Algorithm and Noise Ratio to calculate average accuracies\n",
    "grouped_data = filtered_data.groupby(['Algorithm', 'Noise_Ratio']).agg({'Accuracy': 'mean'}).reset_index()\n",
    "\n",
    "# Pivot the data to get a structure suitable for LaTeX table generation\n",
    "pivot_data = grouped_data.pivot(index='Noise_Ratio', columns='Algorithm', values='Accuracy')\n",
    "   \n",
    "# Generate LaTeX table\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\begin{tabular}{|c|c|c|c|}\n",
    "\\\\hline\n",
    "\\\\textbf{Noise Ratio} & \\\\textbf{GCN (\\\\%)} & \\\\textbf{GTM (\\\\%)} & \\\\textbf{TMClassifier (\\\\%)} \\\\\\\\ \\\\hline\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over the pivot data to construct the table rows\n",
    "for noise_ratio, row in pivot_data.iterrows():\n",
    "    latex_table += f\"{noise_ratio} & \"\n",
    "    latex_table += f\"{row['Graph NN']:.2f} & {row['GraphTM']:.2f} & {row['TMClassifier']:.2f} \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "latex_table += \"\\\\end{tabular}\\n\"\n",
    "latex_table += \"\\\\caption{Average accuracy comparison of GCN, GraphTM, and TMClassifier for varying noise ratios.}\\n\"\n",
    "latex_table += \"\\\\label{tab:recomm_sys_accuracy}\\n\"\n",
    "latex_table += \"\\\\end{table}\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "\\textbf{Noise Ratio} & \\textbf{GCN (\\%)} & \\textbf{GraphTM (\\%)} & \\textbf{TMClassifier (\\%)} \\\\ \\hline\n",
      "0.005 & 83.39 \\pm 4.83 & 98.73 \\pm 0.12 & 76.73 \\pm 0.14 \\\\ \\hline\n",
      "0.01 & 85.55 \\pm 6.99 & 98.35 \\pm 0.08 & 74.87 \\pm 0.12 \\\\ \\hline\n",
      "0.02 & 83.57 \\pm 5.76 & 97.73 \\pm 0.13 & 72.24 \\pm 0.26 \\\\ \\hline\n",
      "0.05 & 82.13 \\pm 5.30 & 94.61 \\pm 0.34 & 63.86 \\pm 0.34 \\\\ \\hline\n",
      "0.1 & 75.93 \\pm 3.89 & 89.85 \\pm 0.29 & 49.48 \\pm 0.38 \\\\ \\hline\n",
      "0.2 & 64.12 \\pm 3.07 & 78.73 \\pm 0.75 & 20.13 \\pm 0.04 \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\caption{Average accuracy and standard deviation comparison of GCN, GraphTM, and TMClassifier for varying noise ratios.}\n",
      "\\label{tab:recomm_sys_accuracy}\n",
      "\\{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"experiment_results.csv\")\n",
    "exp_id = \"20250409090514\"\n",
    "data['Exp_id'] = data['Exp_id'].astype(str)\n",
    "\n",
    "# Filter the data for the specified experiment ID\n",
    "filtered_data = data[data['Exp_id'] == exp_id]\n",
    "\n",
    "# Group the data by Algorithm and Noise Ratio to calculate average accuracies and standard deviations\n",
    "grouped_data = filtered_data.groupby(['Algorithm', 'Noise_Ratio']).agg(\n",
    "    Accuracy_mean=('Accuracy', 'mean'),\n",
    "    Accuracy_std=('Accuracy', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the data to get a structure suitable for LaTeX table generation\n",
    "pivot_data_mean = grouped_data.pivot(index='Noise_Ratio', columns='Algorithm', values='Accuracy_mean')\n",
    "pivot_data_std = grouped_data.pivot(index='Noise_Ratio', columns='Algorithm', values='Accuracy_std')\n",
    "\n",
    "# Start building the LaTeX table\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{table}[h!]\n",
    "\\\\centering\n",
    "\\\\begin{tabular}{|c|c|c|c|}\n",
    "\\\\hline\n",
    "\\\\textbf{Noise Ratio} & \\\\textbf{GCN (\\\\%)} & \\\\textbf{GraphTM (\\\\%)} & \\\\textbf{TMClassifier (\\\\%)} \\\\\\\\ \\\\hline\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over the pivot data to construct the table rows with mean and standard deviation\n",
    "for noise_ratio in pivot_data_mean.index:\n",
    "    gcn_mean = pivot_data_mean.loc[noise_ratio, 'Graph NN']\n",
    "    gcn_std = pivot_data_std.loc[noise_ratio, 'Graph NN']\n",
    "    \n",
    "    graph_tm_mean = pivot_data_mean.loc[noise_ratio, 'GraphTM']\n",
    "    graph_tm_std = pivot_data_std.loc[noise_ratio, 'GraphTM']\n",
    "    \n",
    "    tm_classifier_mean = pivot_data_mean.loc[noise_ratio, 'TMClassifier']\n",
    "    tm_classifier_std = pivot_data_std.loc[noise_ratio, 'TMClassifier']\n",
    "\n",
    "    latex_table += f\"{noise_ratio} & \"\n",
    "    latex_table += f\"{gcn_mean:.2f} \\\\pm {gcn_std:.2f} & \"\n",
    "    latex_table += f\"{graph_tm_mean:.2f} \\\\pm {graph_tm_std:.2f} & \"\n",
    "    latex_table += f\"{tm_classifier_mean:.2f} \\\\pm {tm_classifier_std:.2f} \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "latex_table += \"\\\\end{tabular}\\n\"\n",
    "latex_table += \"\\\\caption{Average accuracy and standard deviation comparison of GCN, GraphTM, and TMClassifier for varying noise ratios.}\\n\"\n",
    "latex_table += \"\\\\label{tab:recomm_sys_accuracy}\\n\"\n",
    "latex_table += \"\\\\{table}\"\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages across all noise ratios:\n",
      "Algorithm: Graph NN, Average Accuracy: 79.11%, Average Total Time: 44.80s\n",
      "Algorithm: GraphTM, Average Accuracy: 93.00%, Average Total Time: 133.75s\n",
      "Algorithm: TMClassifier, Average Accuracy: 59.55%, Average Total Time: 1068.99s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(\"experiment_results.csv\")\n",
    "\n",
    "# Define the experiment ID you want to filter\n",
    "exp_id = \"20250409090514\"\n",
    "\n",
    "# Ensure that Exp_id is treated as a string\n",
    "data['Exp_id'] = data['Exp_id'].astype(str)\n",
    "\n",
    "# Filter the data based on the experiment ID\n",
    "filtered_data = data[data['Exp_id'] == exp_id]\n",
    "\n",
    "# Group the data by Algorithm to calculate average accuracies and total time across all noise ratios\n",
    "grouped_data = filtered_data.groupby('Algorithm').agg({'Accuracy': 'mean', 'Total_Time': 'mean'}).reset_index()\n",
    "\n",
    "# Print the average results for each algorithm across all noise ratios\n",
    "print(\"Averages across all noise ratios:\")\n",
    "for _, row in grouped_data.iterrows():\n",
    "    algorithm = row['Algorithm']\n",
    "    average_accuracy = row['Accuracy']\n",
    "    average_total_time = row['Total_Time']\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Algorithm: {algorithm}, Average Accuracy: {average_accuracy:.2f}%, Average Total Time: {average_total_time:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
